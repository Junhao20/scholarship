library(ggplot2)
library(dplyr)
library(forecast)
weather_data <- read.csv("data/weather.csv", header = TRUE)
weather_data$Time.of.Observation <- as.POSIXct(weather_data$Time.of.Observation, format = "%Y-%m-%dT%H:%M:%S")
str(weather_data)
weather_data <- weather_data %>% filter(!is.na(Sea.Level.Pressure))
sea_level_ts <- ts(weather_data$Sea.Level.Pressure, frequency = 24)
decomposed_ts <- decompose(sea_level_ts)
plot(decomposed_ts, main = "Decomposition of Sea Level Pressure Time Series")
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(forecast)
# Read the dataset
weather_data <- read.csv("data/weather.csv", header = TRUE)
# Convert the Time of Observation column to proper datetime format
weather_data$Time.of.Observation <- as.POSIXct(weather_data$Time.of.Observation, format = "%Y-%m-%dT%H:%M:%S")
# Verify the structure of the dataset
str(weather_data)
# Remove rows with missing Sea Level Pressure values
weather_data <- weather_data %>% filter(!is.na(Sea.Level.Pressure))
# Create a time series object for Sea Level Pressure
sea_level_ts <- ts(weather_data$Sea.Level.Pressure, frequency = 24)
# Decompose the time series
decomposed_ts <- decompose(sea_level_ts)
# Plot the decomposed components
plot(decomposed_ts)  # Removed the "main" argument
# Additional ggplot for better visualization
ggplot(weather_data, aes(x = Time.of.Observation, y = Sea.Level.Pressure)) +
geom_line(color = "blue") +
labs(title = "Sea Level Pressure Over Time",
x = "Time of Observation",
y = "Sea Level Pressure") +
theme_minimal()
# plot 1
library(plotly)
library(dplyr)
data <- read.csv("data/unemployment_full.csv", header = TRUE)
head(data)
data$Date <- as.Date(paste(data$Year, data$Period, "01", sep = "-"), format = "%Y-%b-%d")
head(data)
head(data)
data$Year <- as.numeric(data$Year)
# plot 1
state_avg <- data %>%
group_by(State) %>%
summarise(avg_rate = mean(`unemployment.rate`)) %>%
arrange(desc(avg_rate))
top_states <- state_avg$State[1:20]
data_filtered <- data %>% filter(State %in% top_states)
library(RColorBrewer)
colors <- colorRampPalette(brewer.pal(8, "Set2"))(length(unique(data_filtered$State)))
fig <- plot_ly(data_filtered,
x = ~State,
y = ~`unemployment.rate`,
color = ~Period,
colors = colors,
frame = ~Year,
type = 'scatter',
mode = 'lines+markers') %>%
layout(title = "Animated Scatter Plot of Unemployment Rate Over Time for All States",
xaxis = list(title = "Date"),
yaxis = list(title = "Unemployment Rate"))
fig
ggplot(data, aes(x = year, y = unemployment_rate, group = state, color = state)) +
geom_line() +
facet_wrap(~ state, scales = "free_y") +
theme_minimal() +
labs(
title = "Unemployment Rate Trends by State",
x = "Year",
y = "Unemployment Rate"
)
library(readr)
library(ggplot2)
ggplot(data, aes(x = year, y = unemployment_rate, group = state, color = state)) +
geom_line() +
facet_wrap(~ state, scales = "free_y") +
theme_minimal() +
labs(
title = "Unemployment Rate Trends by State",
x = "Year",
y = "Unemployment Rate"
)
library(readr)
library(ggplot2)
ggplot(data, aes(x = Year, y = unemployment.rate, group = state, color = state)) +
geom_line() +
facet_wrap(~ State, scales = "free_y") +
theme_minimal() +
labs(
title = "Unemployment Rate Trends by State",
x = "Year",
y = "Unemployment Rate"
)
library(readr)
library(ggplot2)
ggplot(data, aes(x = Date, y = unemployment.rate, group = State, color = State)) +
geom_line() +
facet_wrap(~ State, scales = "free_y") +
theme_minimal() +
labs(
title = "Unemployment Rate Trends by State",
x = "Date",
y = "Unemployment Rate"
) +
theme(
legend.position = "none", # Remove legend for cleaner facets
strip.text = element_text(size = 8) # Adjust facet labels size
)
library(readr)
library(ggplot2)
ggplot(data, aes(x = Date, y = unemployment.rate, group = State, color = State)) +
geom_line() +
facet_wrap(~ State, scales = "free_y") +
theme_minimal() +
labs(
title = "Unemployment Rate Trends by State",
x = "Date",
y = "Unemployment Rate"
) +
theme(
legend.position = "none", # Remove legend for cleaner facets
strip.text = element_text(size = 8), # Adjust facet labels size
axis.text.x = element_text(angle = 45, hjust = 1) # Tilt x-axis labels
)
library(readr)
library(ggplot2)
ggplot(data, aes(x = Date, y = unemployment.rate, group = State, color = State)) +
geom_line() +
facet_wrap(~ State, scales = "free_y") +
theme_minimal() +
labs(
title = "Unemployment Rate Trends by State",
x = "Date",
y = "Unemployment Rate"
) +
theme(
legend.position = "none",
strip.text = element_text(size = 8),
axis.text.x = element_text(angle = 45, hjust = 1),
axis.text.y = element_text(angle = 45, hjust = 1)
)
library(tidyverse)
library(ggplot2)
library(forecast)
library(astsa)
library(xts)
library(tseries)
library(fpp2)
library(fma)
library(lubridate)
library(tidyverse)
library(TSstudio)
library(quantmod)
library(tidyquant)
library(plotly)
library(ggplot2)
library(forecast)
library(tsibble)
library(fpp3)
library(lubridate)
df <- read.csv("indeed.csv")
colnames(df) <- c("date", "value")
df$date <- seq(as.Date("2020-01-01"), by = "day", length.out = nrow(df))
ts_indeed <- ts(df$value, frequency = 7, start = c(year(min(df$date)), yday(min(df$date))/7))
#| warning: false
library(forecast)
library(tsibble)
library(fpp3)
library(lubridate)
df <- read.csv("indeed.csv")
colnames(df) <- c("date", "value")
df$date <- seq(as.Date("2020-01-01"), by = "day", length.out = nrow(df))
ts_indeed <- ts(df$value, frequency = 7, start = c(year(min(df$date)), yday(min(df$date))/7))
par(mfrow=c(1,2))
acf(ts_indeed, main="ACF of Indeed Data")
pacf(ts_indeed, main="PACF of Indeed Data")
par(mfrow=c(1,1)) # need difference
diff <- diff(ts_indeed)
par(mfrow=c(1,2))
acf(diff, main="ACF of differenced Indeed Data", lag = 50)
pacf(diff, main="PACF of differenced Indeed Data", lag = 50)
par(mfrow=c(1,1))
diff2 <- diff(diff)
par(mfrow=c(1,2))
acf(diff2, main="ACF of second differenced Indeed Data")
pacf(diff2, main="PACF of second differenced Indeed Data")
par(mfrow=c(1,1))
######################## Check for different combinations ########
#write a funtion
SARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,data){
#K=(p2+1)*(q2+1)*(P2+1)*(Q2+1)
temp=c()
d=2
D=1
s=7
i=1
temp= data.frame()
ls=matrix(rep(NA,9*35),nrow=35)
for (p in p1:p2)
{
for(q in q1:q2)
{
for(P in P1:P2)
{
for(Q in Q1:Q2)
{
if(p+d+q+P+D+Q<=9)
{
model<- Arima(data,order=c(p-1,d,q-1),seasonal=c(P-1,D,Q-1))
ls[i,]= c(p-1,d,q-1,P-1,D,Q-1,model$aic,model$bic,model$aicc)
i=i+1
#print(i)
}
}
}
}
}
temp= as.data.frame(ls)
names(temp)= c("p","d","q","P","D","Q","AIC","BIC","AICc")
temp
}
output=SARIMA.c(p1=1,p2=2,q1=1,q2=2,P1=1,P2=2,Q1=1,Q2=2,data=ts_indeed)
#output
#knitr::kable(output)
output[which.min(output$AIC),]
output[which.min(output$BIC),]
output[which.min(output$AICc),]
auto.arima(ts_indeed)
library(fpp3)
# Convert dataset to tsibble
df <- read.csv("indeed.csv")
colnames(df) <- c("date", "value")
df$date <- seq(as.Date("2020-01-01"), by = "day", length.out = nrow(df))
ts_indeed <- df %>%
as_tsibble(index = date)
# Define time series cross-validation function (one-step ahead)
cv_one_step <- ts_indeed %>%
stretch_tsibble(.init = 365, .step = 1) %>%  # Expand window, step forward by 1 day
model(
ARIMA_020 = ARIMA(value ~ pdq(0,2,0) + PDQ(1,1,1) + season(7)),
ARIMA_322 = ARIMA(value ~ pdq(3,2,2) + PDQ(1,0,1) + season(7))
) %>%
forecast(h = 1) %>%  # One-step ahead forecast
accuracy(ts_indeed)
print(cv_one_step)
library(fpp3)
cv_one_step <- ts_indeed %>%
stretch_tsibble(.init = 365, .step = 1) %>%
model(
ARIMA_020 = ARIMA(value ~ pdq(0,2,0) + PDQ(1,1,1) + season(7) + 1),  # Explicitly include constant
ARIMA_322 = ARIMA(value ~ pdq(3,2,2) + PDQ(1,0,1) + season(7) + 1)   # Explicitly include constant
) %>%
forecast(h = 1) %>%
accuracy(ts_indeed)
library(fpp3)
library(forecast)
df <- read.csv("indeed.csv")
colnames(df) <- c("date", "value")
df$date <- as.Date(df$date, format = "%Y-%m-%d")
ts_ai <- ts(df$value, frequency = 7, start = c(as.numeric(format(min(df$date), "%Y")), as.numeric(format(min(df$date), "%j"))/7))
fit_arima311 <- Arima(ts_ai, order = c(3,1,1))
fit_sarima114 <- Arima(ts_ai, order = c(1,1,4), seasonal = list(order = c(0,0,1), period = 12))
accuracy_arima311 <- accuracy(fit_arima311)
accuracy_sarima114 <- accuracy(fit_sarima114)
model_comparison <- data.frame(
Model = c("ARIMA(3,1,1)", "ARIMA(1,1,4)(0,0,1)[12]"),
AIC = c(fit_arima311$aic, fit_sarima114$aic),
BIC = c(fit_arima311$bic, fit_sarima114$bic),
RMSE = c(accuracy_arima311[nrow(accuracy_arima311), "RMSE"],
accuracy_sarima114[nrow(accuracy_sarima114), "RMSE"]),
MAPE = c(accuracy_arima311[nrow(accuracy_arima311), "MAPE"],
accuracy_sarima114[nrow(accuracy_sarima114), "MAPE"])
)
print(model_comparison)
library(forecast)
library(lubridate)
df <- read.csv("indeed.csv")
colnames(df) <- c("date", "value")
df$date <- as.Date(df$date, format = "%Y-%m-%d")
ts_ai <- ts(df$value, frequency = 7, start = c(as.numeric(format(min(df$date), "%Y")), as.numeric(format(min(df$date), "%j"))/7))
s <- 12
len <- length(ts_ai)
st <- tsp(ts_ai)[1] + (s-1)/s
one_step_forecasts <- vector("numeric", len-s)
s_step_forecasts <- vector("numeric", len-s)
actuals <- vector("numeric", len-s)
for (i in 1:(len - s)) {
model <- Arima(window(ts_ai, end = st + i + s - 1),
order = c(1,1,4),
seasonal = list(order = c(0,0,1), period = 12))
one_step_forecasts[i] <- forecast(model, h=1)$mean
s_step_forecasts[i] <- forecast(model, h=s)$mean[s]
actuals[i] <- ts_ai[i + s]
}
library(forecast)
library(lubridate)
df <- read.csv("indeed.csv")
colnames(df) <- c("date", "value")
df$date <- seq(as.Date("2020-01-01"), by = "day", length.out = nrow(df))
ts_ai <- ts(df$value, frequency = 7, start = c(year(min(df$date)), yday(min(df$date))/7))
s <- 12
len <- length(ts_ai)
one_step_forecasts <- numeric(len - s)
s_step_forecasts <- numeric(len - s)
actuals <- numeric(len - s)
for (i in 1:(len - s)) {
train_data <- window(ts_ai, end = time(ts_ai)[i + s - 1])
model <- Arima(train_data, order = c(1,1,4), seasonal = list(order = c(0,0,1), period = 12))
one_step_forecasts[i] <- forecast(model, h=1)$mean
s_step_forecasts[i] <- forecast(model, h=s)$mean[s]
actuals[i] <- ts_ai[i + s]
}
library(forecast)
library(lubridate)
df <- read.csv("indeed.csv")
colnames(df) <- c("date", "value")
df$date <- seq(as.Date("2020-01-01"), by = "day", length.out = nrow(df))
ts_indeed <- ts(df$value, frequency = 7, start = c(year(min(df$date)), yday(min(df$date))/7))
s <- 7
len <- length(ts_indeed)
one_step_forecasts <- numeric(len - s)
s_step_forecasts <- numeric(len - s)
actuals <- numeric(len - s)
for (i in 1:(len - s)) {
train_data <- window(ts_indeed, end = time(ts_indeed)[i + s - 1])
model <- Arima(train_data, order = c(1,1,4), seasonal = list(order = c(0,0,1), period = 7))
one_step_forecasts[i] <- forecast(model, h=1)$mean
s_step_forecasts[i] <- forecast(model, h=s)$mean[s]
actuals[i] <- ts_indeed[i + s]
}
library(forecast)
library(lubridate)
df <- read.csv("indeed.csv")
colnames(df) <- c("date", "value")
df$date <- seq(as.Date("2020-01-01"), by = "day", length.out = nrow(df))
ts_indeed <- ts(df$value, frequency = 7, start = c(year(min(df$date)), yday(min(df$date))/7))
s <- 7
len <- length(ts_indeed)
one_step_forecasts <- numeric(len - s)
s_step_forecasts <- numeric(len - s)
actuals <- numeric(len - s)
for (i in 1:(len - s)) {
train_data <- window(ts_indeed, end = time(ts_indeed)[i + s - 1])
# Force stationarity by setting `stationary=TRUE`
model <- Arima(train_data, order = c(1,1,4), seasonal = list(order = c(0,0,1), period = 7),
method = "ML", include.constant = FALSE)
one_step_forecasts[i] <- forecast(model, h=1)$mean
s_step_forecasts[i] <- forecast(model, h=s)$mean[s]
actuals[i] <- ts_indeed[i + s]
}
library(forecast)
library(lubridate)
df <- read.csv("indeed.csv")
colnames(df) <- c("date", "value")
df$date <- seq(as.Date("2020-01-01"), by = "day", length.out = nrow(df))
ts_indeed <- ts(df$value, frequency = 7, start = c(year(min(df$date)), yday(min(df$date))/7))
s <- 7
len <- length(ts_indeed)
one_step_forecasts <- numeric(len - s)
s_step_forecasts <- numeric(len - s)
actuals <- numeric(len - s)
for (i in 1:(len - s)) {
train_data <- window(ts_indeed, end = time(ts_indeed)[i + s - 1])
# Force stationarity by setting `stationary=TRUE`
model <- Arima(train_data, order = c(0,2,0), seasonal = list(order = c(1,1,1), period = 7),
method = "ML", include.constant = FALSE)
one_step_forecasts[i] <- forecast(model, h=1)$mean
s_step_forecasts[i] <- forecast(model, h=s)$mean[s]
actuals[i] <- ts_indeed[i + s]
}
library(forecast)
library(lubridate)
df <- read.csv("indeed.csv")
colnames(df) <- c("date", "value")
df$date <- seq(as.Date("2020-01-01"), by = "day", length.out = nrow(df))
ts_indeed <- ts(df$value, frequency = 7, start = c(year(min(df$date)), yday(min(df$date))/7))
s <- 7
len <- length(ts_indeed)
one_step_forecasts <- numeric(len - s)
s_step_forecasts <- numeric(len - s)
actuals <- numeric(len - s)
for (i in 1:(len - s)) {
train_data <- window(ts_indeed, end = i + s - 1)  # Adjusted indexing
# Ensuring stationarity & better parameter estimation
model <- Arima(train_data, order = c(0,2,0), seasonal = list(order = c(1,1,1), period = 7),
method = "ML", include.constant = FALSE)
one_step_forecasts[i] <- forecast(model, h=1)$mean[1]  # Ensure correct indexing
s_step_forecasts[i] <- forecast(model, h=s)$mean[min(s, length(forecast(model, h=s)$mean))]  # Safe index
actuals[i] <- ts_indeed[i + s]
}
library(forecast)
library(lubridate)
df <- read.csv("indeed.csv")
colnames(df) <- c("date", "value")
df$date <- seq(as.Date("2020-01-01"), by = "day", length.out = nrow(df))
ts_indeed <- ts(df$value, frequency = 7, start = c(year(min(df$date)), yday(min(df$date))/7))
s <- 7
len <- length(ts_indeed)
one_step_forecasts <- numeric(len - s)
s_step_forecasts <- numeric(len - s)
actuals <- numeric(len - s)
for (i in 1:(len - s)) {
# Ensure the window is valid
if (i + s - 1 > len) {
break  # Prevents invalid indexing
}
train_data <- window(ts_indeed, end = time(ts_indeed)[i + s - 1])
# Fit SARIMA model
model <- Arima(train_data, order = c(0,2,0), seasonal = list(order = c(1,1,1), period = 7),
method = "ML", include.constant = FALSE)
one_step_forecasts[i] <- forecast(model, h=1)$mean[1]
s_step_forecasts[i] <- forecast(model, h=s)$mean[min(s, length(forecast(model, h=s)$mean))]
actuals[i] <- ts_indeed[i + s]
}
library(forecast)
library(lubridate)
s <- 7
len <- length(ts_indeed)
st <- tsp(ts_indeed)[1] + (s-1)/s
one_step_forecasts <- vector("numeric", len-s)
s_step_forecasts <- vector("numeric", len-s)
actuals <- vector("numeric", len-s)
for (i in 1:(len - s)) {
model <- Arima(window(ts_ai, end = st + i + s - 1),
order = c(0,2,0),
seasonal = list(order = c(1,1,1), period = 7))
one_step_forecasts[i] <- forecast(model, h=1)$mean
s_step_forecasts[i] <- forecast(model, h=s)$mean[s]
actuals[i] <- ts_ai[i + s]
}
library(forecast)
library(lubridate)
df <- read.csv("indeed.csv")
colnames(df) <- c("date", "value")
df$date <- seq(as.Date("2020-01-01"), by = "day", length.out = nrow(df))
ts_indeed <- ts(df$value, frequency = 7, start = c(year(min(df$date)), yday(min(df$date))/7))
s <- 7
len <- length(ts_indeed)
one_step_forecasts <- numeric(len - s)
s_step_forecasts <- numeric(len - s)
actuals <- numeric(len - s)
for (i in 1:(len - s)) {
# Ensure we have enough data points
if (i + s - 1 > len || i < 10) {  # Ensure minimum 10 data points
next
}
train_data <- window(ts_indeed, end = time(ts_indeed)[i + s - 1])
if (length(train_data) < 10) {  # Avoid fitting models with very few observations
next
}
model <- Arima(train_data, order = c(0,2,0), seasonal = list(order = c(1,1,1), period = 7),
method = "ML", include.constant = FALSE)
one_step_forecasts[i] <- forecast(model, h=1)$mean[1]
s_step_forecasts[i] <- forecast(model, h=s)$mean[min(s, length(forecast(model, h=s)$mean))]
actuals[i] <- ts_indeed[i + s]
}
# Compute errors safely
valid_indices <- which(!is.na(one_step_forecasts) & !is.na(s_step_forecasts) & !is.na(actuals))
one_step_errors <- actuals[valid_indices] - one_step_forecasts[valid_indices]
s_step_errors <- actuals[valid_indices] - s_step_forecasts[valid_indices]
# Compute accuracy metrics
one_step_mae <- mean(abs(one_step_errors), na.rm = TRUE)
one_step_rmse <- sqrt(mean(one_step_errors^2, na.rm = TRUE))
s_step_mae <- mean(abs(s_step_errors), na.rm = TRUE)
s_step_rmse <- sqrt(mean(s_step_errors^2, na.rm = TRUE))
results <- data.frame(
Metric = c("1-Step MAE", "1-Step RMSE", "7-Step MAE", "7-Step RMSE"),
Value = c(one_step_mae, one_step_rmse, s_step_mae, s_step_rmse)
)
print(results)
#| vscode: {languageId: r}
# IMPORT LIBRARIES
library(ISLR)
library(gam)
install.packages("gam")
shiny::runApp('Desktop/scholarship/app')
runApp('Desktop/scholarship/app')
runApp('Desktop/scholarship/app')
runApp('Desktop/scholarship/app')
runApp('Desktop/scholarship/app')
runApp('Desktop/scholarship/app')
runApp('Desktop/scholarship/app')
remove.packages("ggplot2")
remove.packages("scales")
remove.packages("plotly")
remove.packages("rlang")
remove.packages("cli")     # This sometimes causes trouble too
# Restart RStudio manually here
.rs.restartR()
install.packages("ggplot2", dependencies = TRUE)
install.packages("plotly")
install.packages("dplyr")
install.packages("ggplot2", dependencies = TRUE)
install.packages("scales")
install.packages("plotly")
install.packages("shiny")
install.packages("dplyr")
shiny::runApp('Desktop/scholarship/app')
install.packages("leaflet")
runApp('Desktop/scholarship/app')
runApp('Desktop/scholarship/app')
runApp('Desktop/scholarship/app')
runApp('Desktop/scholarship/app')
runApp('Desktop/scholarship/app')
runApp('Desktop/scholarship/app')
runApp('Desktop/scholarship/app')
runApp('Desktop/scholarship/app')
runApp('Desktop/scholarship/app')
shiny::runApp()
